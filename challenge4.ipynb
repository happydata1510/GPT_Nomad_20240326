{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL의 내용 가져오기\n",
    "url = \"https://gist.githubusercontent.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223/raw/d72b9558a11523adbe13300b41321ecd93d331d3/document.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1444, which is longer than the specified 1000\n",
      "Created a chunk of size 1251, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 2313, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n",
      "Created a chunk of size 1673, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1559, which is longer than the specified 1000\n",
      "Created a chunk of size 1200, which is longer than the specified 1000\n",
      "Created a chunk of size 1042, which is longer than the specified 1000\n",
      "Created a chunk of size 1345, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n",
      "Created a chunk of size 1288, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 2247, which is longer than the specified 1000\n",
      "Created a chunk of size 1728, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 텍스트를 청크로 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(text)\n",
    "\n",
    "# 분할된 텍스트에서 문서 생성\n",
    "documents = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 임베딩 생성 및 Chroma에 문서 저장\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=\"\")\n",
    "\n",
    "# 문자열을 Document 객체로 변환\n",
    "documents = [Document(page_content=t) for t in texts]\n",
    "\n",
    "docsearch = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationBufferMemory를 사용하여 체인 생성\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    OpenAI(openai_api_key=\"\"),\n",
    "    docsearch.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: Aaronson은 유죄인가요?\n",
      "답변: 죄인인지 여부를 알 수 없습니다.\n",
      "\n",
      "질문: 그가 테이블에 어떤 메시지를 썼나요?\n",
      "답변: 그 문맥에서는 그가 테이블에 어떤 메시지를 쓴 것에 대한 언급이 없습니다.\n",
      "\n",
      "질문: Julia는 누구인가요?\n",
      "답변: Julia는 위스키스미스의 소설 '1984'에서 중요한 캐릭터로 나오는 여성 캐릭터입니다. 위 스크립트에서는 주인공인 윈스턴이 Julia를 사랑하는 모습이 묘사되어 있습니다. Julia는 윈스턴과 함께 반인권 정부에 저항하고 사랑을 나누는데 중요한 역할을 합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# ConversationBufferMemory를 사용하여 체인 생성\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=\"\"),\n",
    "    docsearch.as_retriever(),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# 체인에 질문하고 답변 출력\n",
    "questions = [\n",
    "    \"Aaronson은 유죄인가요?\",\n",
    "    \"그가 테이블에 어떤 메시지를 썼나요?\", \n",
    "    \"Julia는 누구인가요?\"\n",
    "]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"질문: {question}\")\n",
    "    print(f\"답변: {result['answer']}\\n\")\n",
    "    \n",
    "#끝!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rmx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
